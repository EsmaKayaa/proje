from langchain_community.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from dotenv import load_dotenv
import os

load_dotenv()

# .env'den anahtarÄ± gÃ¼venli ÅŸekilde al
GEMINI_API_KEY = os.getenv("GOOGLE_GENAI_API_KEY")

# build_vector_db.py dosyanÄ±zdaki ayarla uyumlu olmalÄ±dÄ±r!
USE_LOCAL_EMBEDDING = False 

def get_embeddings_model():
    """KullanÄ±lacak embedding modelini dÃ¶ndÃ¼rÃ¼r."""
    if USE_LOCAL_EMBEDDING:
        from langchain_community.embeddings import HuggingFaceEmbeddings
        return HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    else:
        if not GEMINI_API_KEY:
            raise ValueError("Google Gemini API anahtarÄ± bulunamadÄ±. LÃ¼tfen .env dosyanÄ±zÄ± kontrol edin.")
        # GÃ¼ncel ve Ã¶nerilen embedding modelini kullan
        return GoogleGenerativeAIEmbeddings(
            model="text-embedding-004", 
            google_api_key=GEMINI_API_KEY
        )

def run_chatbot():
    # Embedding modelini tanÄ±mla
    embeddings = get_embeddings_model()
    
    # Hata Ã‡Ã¶zÃ¼mÃ¼: Chroma yÃ¼klenirken embedding fonksiyonu belirtilmeli!
    db = Chroma(
        persist_directory="vector_db",
        embedding_function=embeddings 
    )
    retriever = db.as_retriever(search_kwargs={"k": 3})

    if not GEMINI_API_KEY:
         raise ValueError("Google Gemini API anahtarÄ± bulunamadÄ±. LÃ¼tfen .env dosyanÄ±zÄ± kontrol edin.")

    # LLM modeli (GÃ¼ncel model)
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash", 
        google_api_key=GEMINI_API_KEY 
    )

    qa = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        return_source_documents=True
    )

    print("ğŸ’¬ Cybersecurity RAG Chatbot hazÄ±r! (Ã‡Ä±kmak iÃ§in 'quit' yaz.)")

    while True:
        query = input("\nSoru: ").strip()
        if not query:
            continue
        if query.lower() == "quit":
            break

        try:
            print("â³ Cevap aranÄ±yor...")
            output = qa({"query": query})
            answer = output["result"]
            docs = output.get("source_documents", [])

            print("\n--- Cevap ---")
            print(answer)
            print("\n--- Kaynaklar (snippet + url) ---")
            for i, d in enumerate(docs):
                txt = d.page_content
                snippet = txt[:350].replace("\n", " ") + ("..." if len(txt) > 350 else "")
                url = d.metadata.get("source_url", "")
                title = d.metadata.get("source_title", "")
                print(f"\n[{i+1}] {title} {(' - ' + url) if url else ''}\n{snippet}")
        except Exception as e:
            print(f"Hata oluÅŸtu: {e}")
            print("LÃ¼tfen API anahtarÄ±nÄ±zÄ±n doÄŸru olduÄŸundan ve veritabanÄ±nÄ±zÄ±n oluÅŸturulduÄŸundan emin olun.")

if __name__ == "__main__":
    run_chatbot()
